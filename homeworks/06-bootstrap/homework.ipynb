{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Permutation Testing, Percentiles, and Bootstrapping\n",
    "\n",
    "## Due Tuesday, November 16th, 11:59pm\n",
    "\n",
    "Welcome to Homework 6! This homework will cover:\n",
    "\n",
    "- Percentiles: see [DDS 24.1](https://eldridgejm.github.io/dive_into_data_science/08-estimation/2_confidence_intervals.html?highlight=percentile#percentiles)\n",
    "- Permutation Testing: see [DDS 22](https://eldridgejm.github.io/dive_into_data_science/07-hypothesis_testing/2_permutation_tests.html)\n",
    "- Bootstrapping: see [DDS 23](https://eldridgejm.github.io/dive_into_data_science/08-estimation/1_bootstrap.html) and [DDS 24](https://eldridgejm.github.io/dive_into_data_science/08-estimation/2_confidence_intervals.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "This assignment is due Tuesday, November 16 at 11:59pm. You are given six slip days thoughout the quarter to extend deadlines. See the syllabus for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "**Important**: For homeworks, the `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). These are great questions for office hours (schedule on Canvas) or your team's chatroom on Campuswire. Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "import babypandas as bpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ramen Ratings üçú"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/menya.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will work with a dataset of ramen ratings from [Kaggle](https://urldefense.proofpoint.com/v2/url?u=https-3A__www.kaggle.com_residentmario_ramen-2Dratings&d=DwIGAw&c=-35OiAkTchMrZOngvJPOeA&r=woEa-rRtUsyMszh00E6AGA&m=_XHb3nCWWiNqq3acPLyeuNtqIdhJCZzDL47aoLYnph2ky7XXFqm3CMFxNiw_jIZy&s=I3GnaTOS519yH3qgraViX-ClRQ3ymN_NrjZKqQgwOts&e=). The data has been cleaned and condensed for the purposes of this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ramen data contains five columns: `'Brand'`, `'Variety'`, `'Style'`, `'Country'`, `'Stars'`. Let's read it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramen = bpd.read_csv('data/ramen.csv')\n",
    "ramen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1**. The `'Stars'` column currently contains strings. Because we cannot do numerical calculations with strings, we need to convert these values into floats. In your `ramen` DataFrame, replace the `'Stars'` column so that all the data values are floats instead of strings. Find the min, max, mean, and median star ratings of all the ramen, and save these values (in this order) in an *array* called `stars_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stars_stats = ...\n",
    "stars_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** Using the `ramen` DataFrame, calculate the difference between the mean star ratings of Japanese and American ramen. Assign your answer to `observed_difference`.\n",
    "\n",
    "$$\\text{observed difference} = \\text{mean Japan stars} - \\text{mean USA stars}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_difference = ...\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** Interpret in words the number you obtained for `observed_difference` and assign either 1, 2, 3, or 4 to `q1_3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In our sample, the mean USA stars is lower than the mean Japan stars by about 34 percent.\n",
    "2. In our sample, the mean USA stars is higher than the mean Japan stars by about 34 percent.\n",
    "3. In our sample, the mean USA stars is lower than the mean Japan stars by about 0.34 stars.\n",
    "4. In our sample, the mean Japan stars is lower than the mean USA stars by about 0.34 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now we want to conduct a permutation test (i.e. an A/B test) to see if it is by chance that the average star rating for Japanese ramen is greater than the average star rating for American ramen, or if Japanese ramen really does have higher ratings than American ramen on average. \n",
    "\n",
    "**Null hypothesis:** Star ratings of Japanese ramen and American ramen come from the same distribution.  \n",
    "**Alternative hypothesis:** Star ratings of Japanese ramen are higher on average than star ratings of American ramen.\n",
    "\n",
    "**Question 1.4.** For our permutation test, we'll need to shuffle a DataFrame with only the rows for American and Japanese ramen. For simplicity, we'll also keep only the columns we need, `'Stars'` and `'Country'`. Set `japan_usa_ramen`to this DataFrame with only the rows and columns needed for our permutation test.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "japan_usa_ramen = ...\n",
    "japan_usa_ramen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5.** To perform the permutation test, 1000 times, create two random groups by shuffling the `'Stars'` column of `japan_usa_ramen`. Don't change the `'Country'` column. For each pair of random groups, calculate the difference in mean star ratings (Japan minus USA) and store your 1000 differences in the `differences` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = np.array([]) \n",
    "for i in np.arange(1000):\n",
    "    ...\n",
    "\n",
    "# Just display the first ten differences.\n",
    "differences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6.** Which of the following choices best describes the purpose of shuffling the data in a permutation test? Assign either 1, 2, or 3 to `q1_6`.\n",
    "1. The shuffling is a special case of the bootstrap and allows us to produce interval estimates.\n",
    "2. The shuffling simulates the act of generating new data under the null hypothesis which we can use in testing our hypothesis.\n",
    "3. The shuffling mitigates noise in our data by generating new permutations of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_6 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7.** Compute a p-value for the hypothesis test and assign your answer to `p_val`. To decide whether to use `<=` or `>=` in the calculation of the p-value, think about whether larger values or smaller values of our test statistic favor the alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val = ...\n",
    "p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.8.** Assign the variable `q1_8` to a `list` of all the true statements below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We reject the null hypothesis at the 0.05 significance level.\n",
    "2. We fail to reject the null hypothesis at the 0.05 significance level.\n",
    "3. We accept the null hypothesis at the 0.05 significance level.\n",
    "4. We reject the null hypothesis at the 0.01 significance level.\n",
    "5. We fail to reject the null hypothesis at the 0.01 significance level.\n",
    "6. We accept the null hypothesis at the 0.01 significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_8 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.9.** Suppose in this question you had shuffled the `'Country'` column and kept the `'Stars'` column in the same order. Which of the following is a true statement? Assign `q1_9` to either 1, 2, 3, or 4.\n",
    "\n",
    "\n",
    "1. Your new p-value from shuffling `'Country'` would be 1 - (old p-value), where the old p-value is from shuffling `'Stars'`.\n",
    "2. We would conclude that Japanese ramen has lower star ratings than American ramen.\n",
    "3. There would be no difference in the conclusion of the test if we had shuffled the `'Country'` column instead.\n",
    "4. The `'Country'` column cannot be shuffled because it is a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_9 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Percentiles at Starbucks ‚òï"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentiles associate numbers in a dataset to their positions when the dataset is sorted in ascending order.\n",
    "\n",
    "Given any sequence (i.e. list, array, or Series) of numerical values, imagine sorting the values in ascending order, to create a ranked sequence. Roughly speaking, the $p$th percentile of this sequence is the value that is $p$ percent of the way through the sequence. For example, the 10th percentile is only 10% of the way through (towards the beginning), the 50th percentile is halfway through (towards the middle), and the 90th percentile is 90% of the way through (towards the end).\n",
    "\n",
    "There are many different ways to precisely define a percentile. In this class, we'll consider two different approaches. You should think of these as two separate, different ways to define a percentile. They don't always agree!\n",
    "\n",
    "### The mathematical definition\n",
    "\n",
    "> Let $p$ be a number between 0 and 100. The $p$th percentile of a collection is the smallest value in the collection that is *at least as large* as $p$% of all the values. \n",
    "\n",
    "By this definition, any percentile between 0 and 100 can be computed for any collection of values and is always an element of the collection. \n",
    "\n",
    "Suppose there are $n$ elements in the collection. To find the $p$th percentile:\n",
    "\n",
    "1. Sort the collection in increasing order.\n",
    "2. Define $h$ to be $p\\%$ of $n$: \n",
    "\n",
    "$$h = \\frac p{100} \\cdot n$$\n",
    "\n",
    "3. If $h$ is an integer, define $k = h$. Otherwise, let $k$ be the smallest integer greater than $h$.\n",
    "\n",
    "4. Take the $k$th element of the sorted collection\n",
    "    - Start counting from 1, not 0.\n",
    "\n",
    "### The `numpy` definition\n",
    "\n",
    "- The `numpy` package provides a function to calculate percentiles, `np.percentile(array, p)`, which returns the `p`th percentile of `array`.\n",
    "- The `numpy` method of calculating percentile is slightly different than ours.\n",
    "    - The result need not be an element of the array. \n",
    "    - Details are unimportant, just know that our mathematical definition does not always match `np.percentile`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `starbucks.csv` contains some nutritional information on menu items at Starbucks. The data comes from [Kaggle](https://www.kaggle.com/starbucks/starbucks-menu?select=starbucks_drinkMenu_expanded.csv). The columns include `'Category'`, `'Beverage'`, `'Calories'`, `'Total Fat (g)'`, `'Total Carbohydrates (g)'`, `'Sugars (g)'`, `'Protein (g)'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "starbucks = bpd.read_csv('data/starbucks.csv')\n",
    "starbucks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.** Pick the appropriate bins to plot a histogram showing the distribution of `'Calories'`, then create the histogram.\n",
    "\n",
    "Use one of the following:\n",
    "\n",
    "-  `calorie_bins = np.arange(0, 60, 50)`\n",
    "-  `calorie_bins = np.arange(0, 600, 50)`\n",
    "-  `calorie_bins = np.arange(0, 6000, 50)`\n",
    "-  `calorie_bins = np.arange(0, 60000, 50)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calorie_bins = ...\n",
    "\n",
    "# Now create a density histogram showing the distribution of 'Calories' that uses calorie_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** Consider only the Frappuccinos prepared with whole milk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whole_milk_frap = (starbucks[(starbucks.get('Category').str.contains('Frappuccino')) \\\n",
    "                             & (starbucks.get('Beverage_prep') == 'Whole Milk')] )\n",
    "whole_milk_frap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the `'Calories'` data for these whole milk Frappuccinos and store them as an array called `frap_cals`. We'll sort the array, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frap_cals = np.array(whole_milk_frap.get('Calories'))\n",
    "frap_cals = np.sort(frap_cals)\n",
    "frap_cals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the 80th percentile of `frap_cals` using the procedure given above. Set `n` to be the number of elements in `values`. Set `k` to be the smallest integer greater than $\\frac {80}{100} \\cdot n$.  Assign the 80th percentile of the array `values` to `eightieth_percentile_frap`.\n",
    "\n",
    "You must use the variables provided for you when solving this problem. For this problem, **do not** use `np.percentile()`.\n",
    "\n",
    "*Hint:* `np.ceil` will round up a number to the next nearest whole number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = ...\n",
    "k = ...\n",
    "\n",
    "# Don't change this. In order to proceed, k needs to be stored as an int, not a float.\n",
    "# This line is not changing the mathematical value of k, just how it is stored.\n",
    "k = int(k)\n",
    "\n",
    "eightieth_percentile_frap = ...\n",
    "eightieth_percentile_frap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Now we'll compare the 80th percentile of calories in whole milk Frappuccino beverages with the 80th percentile of calories in coffee beverages. \n",
    "\n",
    "Create a DataFrame called `coffee` containing only the beverages with a `'Category'` of `'Coffee'`. Calculate the 80th percentile of calories in these beverages, using the same mathematical procedure, and  assign to the variable `absolute_difference` the absolute difference in the 80th percentile of calories for whole milk Frappuccinos and coffee.\n",
    "\n",
    "As before, use the variables provided and **do not** use `np.percentile()`.\n",
    "\n",
    "*Hint*: Remember to sort the calories using `np.sort` before computing percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = ...\n",
    "\n",
    "n_2 = ...\n",
    "k_2 = ...\n",
    "\n",
    "k_2 = int(k_2) # Don't change this.\n",
    "\n",
    "eightieth_percentile_coffee = ...\n",
    "\n",
    "absolute_difference = ...\n",
    "absolute_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Say that Starbucks wants to create a new whole milk Frappuccino beverage for the end of the year called the \"Peace Out 2021 Frappuccino\". This beverage will have 365 calories, one for every day of the year!\n",
    "\n",
    "Consider a new collection of values, containing all the values in `frap_cals`, plus one more, 365. For what integer values of $p$ would we be able to say that this new collection of values has 365 as its $p$th percentile? Create a `list` called `percentile_range` of all integer values of $p$ such that the $p$th percentile of the new collection equals 365, according to the mathematical definition of percentile. **Do not** use `np.percentile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_collection = np.append(frap_cals, 365)\n",
    "new_collection = np.sort(new_collection)\n",
    "new_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_range = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5**. The first quartile of a numerical collection is the 25th percentile, the second quartile is the 50th percentile, and the third quartile is the 75th percentile. Quartiles are so named because they divide the collection into quarters.\n",
    "\n",
    "Make a list called `sugar_quartiles` that contains the values for the first, second, and third quartiles (in that order) of the `'Sugars (g)'` data provided in `starbucks`. For this problem, calculate the percentiles using `np.percentile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "sugar_quartiles = ...\n",
    "sugar_quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Late Night Nuggets üåô"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are a chicken nugget lover and a regular at McDonald's (especially late at night). When you go with your brother to get your third 4 piece Chicken McNuggets order of the week, you notice that one of your nuggets is extremely small. You start to wonder if you're better off getting your nuggets from Wendy's instead. Your brother tells you that McDonald's nuggets have always been this small, but you are doubtful and decide to investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.** Ideally, you would want to figure out the exact mean weight of *all* McDonald's nuggets. However, it's not feasible to do so. Therefore, you want to collect a sample of McDonald nuggets to obtain a ____________ statistic to estimate the ____________ parameter.\n",
    "\n",
    "Complete the sentence above by filling in the blanks. Set `q3_1` to 1, 2, 3, or 4.\n",
    "\n",
    "1. population; sample\n",
    "2. sample; population\n",
    "3. test; population\n",
    "4. test; sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, you have a friend named Donald who works at McDonald's. He agrees to weigh 30 nuggets during his shift. Even better, you have another friend named Wendy who works at Wendy's. She agrees to weigh 30 nuggets during her shift at Wendy's.  Let's look at all the data that Donald and Wendy collected. Each entry represent the weight of one nugget, in grams.\n",
    "\n",
    "Note: While the story about this data is obviously made-up, [the data is real](https://www.kaggle.com/michigan2000/weight-of-chicken-nuggets). Actual chicken nuggets from McDonald's and Wendy's were weighed! üê•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nugget_data = bpd.read_csv('data/nuggets.csv')\n",
    "nugget_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** The first few tasks we'll look at will only involve the nuggets in our sample from McDonald's. Below, assign `mcd_only` to a DataFrame with only the nuggets in our sample from McDonald's. Then, assign `mcd_mean` to the mean weight of the McDonald's nuggets in our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd_only = ...\n",
    "mcd_mean = ...\n",
    "mcd_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're done! Or are you? You have a single estimate (called a *point estimate*) for the true mean weight of McDonald's nuggets. However, you don't know how accurate your estimate is, and you don't know how much your estimate could have varied, had you started with a different sample. In other words, you have an estimate, but you don't have a sense of how good that estimate is. \n",
    "\n",
    "This is where the idea of resampling via the [bootstrap](https://eldridgejm.github.io/dive_into_data_science/08-estimation/1_bootstrap.html) comes in. Let's assume that our original sample resembles the population fairly well. We can then resample from our original sample to produce even more samples. From each of these resamples, we can produce another estimate, which gives us a whole distribution of how the estimate might have turned out if our sample were different. We can then use this distribution to produce an interval estimate for the true mean weight of McDonald's nuggets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** Complete the following code to produce 1000 bootstrapped estimates for the  *mean* weight of McDonald's nuggets. Store your 1000 estimates in an array called `resample_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_means = ...\n",
    "for i in np.arange(1000):\n",
    "    resample = ...\n",
    "    resample_mean = ...\n",
    "    resample_means = ...\n",
    "resample_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: This cell displays a histogram of estimates for the mean weight of McDonald's nuggets\n",
    "bpd.DataFrame().assign(BootstrappedMeans = resample_means).plot(kind='hist', density=True, ec='w');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4.** Using the array `resample_means`, compute an approximate 95% confidence interval for the true mean weight of McDonald's nuggets. Save the lower and upper bounds of the interval as `lower_bound_mcd` and `upper_bound_mcd`, respectively.\n",
    "\n",
    "*Hint:* Use `np.percentile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_mcd = ...\n",
    "upper_bound_mcd = ...\n",
    "\n",
    "#: the confidence interval\n",
    "print(\"Bootstrapped 95% confidence interval for the true mean weight of McDonald's nuggets: [{:f}, {:f}]\".format(lower_bound_mcd, upper_bound_mcd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5.** Which of the following would make the histogram from Question 3.3 narrower? If you believe more than one would, choose the answer with the most substantial effect. Assign to `q3_5` either 1, 2, 3, or 4.\n",
    "1. Starting with a larger sample of 60 nuggets.\n",
    "2. Starting with a smaller sample of 15 nuggets.\n",
    "3. Increasing the number of resamples (repetitions of the bootstrap) to 2000.\n",
    "3. Decreasing the number of resamples (repetitions of the bootstrap) to 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_5 = ...\n",
    "q3_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6.** Suppose you want to estimate the weight of the heaviest McDonald's nugget ever. Would bootstrapping be effective in estimating this weight? Assign `bootstrapping_effective` to True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapping_effective = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7.** Now let's address a different question: how does the average weight of McDonald's nuggets compare to the average weight of Wendy's nuggets? Create a DataFrame called `wendys_only` that contains only the nuggets in our original sample from Wendy's, as you did for McDonald's in Question 3.2.  Then, set `observed_diff_mean` to the difference in mean nugget weight for the McDonald's and Wendy's nuggets in our sample (do McDonald's minus Wendy's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wendys_only = ...\n",
    "observed_diff_mean = ...\n",
    "observed_diff_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there's definitely a difference in mean nugget weight between McDonald's and Wendy's for the 60 nuggets in our sample. But does this reflect a difference in mean nugget weight in the population, or was it just by chance that the nuggets in our sample displayed this difference? Let's do a hypothesis test to find out. We'll state our hypotheses as follows:\n",
    "\n",
    "**Null Hypothesis:** The mean weight of McDonald's nuggets equals the mean weight of Wendy's nuggets. Equivalently, the difference in the mean nugget weight for McDonald's and Wendy's equals 0 grams.\n",
    "\n",
    "**Alternative Hypothesis:** The mean weight of McDonald's nuggets does not equal the mean weight of Wendy's nuggets. Equivalently, the difference in the mean nugget weight for McDonald's and Wendy's does not equal 0 grams.\n",
    "\n",
    "Since we were able to set up our hypothesis test as a question of whether a certain population parameter ‚Äì the difference in mean nugget weight for McDonald's and Wendy's ‚Äì is equal to a certain value, we can **test our hypotheses by constructing a confidence interval** for the parameter. This is the method we used in Lecture 21 to test whether the median salary of Fire-Rescue Department workers was the same as the median salary of all San Diego city employees. You can read more about conducting a hypothesis test with a confidence interval in [DDS 25.3](https://eldridgejm.github.io/dive_into_data_science/08-estimation/3_ht_using_intervals.html#conducting-an-ht-with-a-ci).\n",
    "\n",
    "**Question 3.8.** Compute 1000 bootstrapped estimates for the difference in the mean nugget weight for McDonald's and Wendy's (do McDonald's minus Wendy's). Store your 1000 estimates in the `difference_means` array.\n",
    "\n",
    "Use your `mcd_only` and `wendys_only` DataFrames for this question. You should not use `nugget_data` at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(23) # Don't change this!\n",
    "\n",
    "difference_means = np.array([]) \n",
    "for i in np.arange(1000):\n",
    "    ...\n",
    "\n",
    "# Just display the first ten differences.\n",
    "difference_means[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell displays a histogram of difference_means\n",
    "bpd.DataFrame().assign(BootstrappedDifferenceMeans = difference_means).plot(kind = 'hist', density=True, ec='w');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9.** Compute a 95% confidence interval for the difference in mean weights of McDonald's and Wendy's nuggets (as before, McDonald's minus Wendy's). Assign the left and right endpoints of this confidence interval to `left_endpoint` and `right_endpoint` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_endpoint = ...\n",
    "right_endpoint = ...\n",
    "\n",
    "print(\"Bootstrapped 95% confidence interval for the mean difference in weights of McDonald's and Wendys nuggets:\\n [{:f}, {:f}]\".format(left_endpoint, right_endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.10.** Based on the confidence interval you've created, would you reject the null hypothesis at the 0.05 significance level? Set `reject_null` to True if you would reject the null hypothesis, and False if you would not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_null = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.11.** Suppose we constructed several 95% confidence intervals by collecting several new original samples and bootstrapping each of them. Which of the following is true?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The true parameter has a roughly 95% chance of falling in any given confidence interval.\n",
    "2. Roughly 95% of the population lies within any given confidence interval.\n",
    "3. Roughly 95% of the confidence intervals constructed capture the true parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_11 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.12.** What if Donald and Wendy had recorded all of their data in ounces instead of grams? Would your hypothesis test still come to the same conclusion either way? Set `same_conclusion` to True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.13.** Choose the best tool to test the following claim: <br>\n",
    "> More people prefer McDonald's nuggets to Wendy's nuggets than the other way around.\n",
    "1. standard hypothesis testing\n",
    "2. permutation (A/B) testing\n",
    "3. bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_13 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.14.** Which test statistic(s) could we use to test the claim from 3.13? Put all that are valid into a `list` called `q3_14`.\n",
    "1. The number of people that prefer McDonald's divided by the total number of people, in a given random sample. \n",
    "2. The difference between the proportion of people that prefer McDonald's and the proportion of people that prefer Wendy's, in a given random sample.\n",
    "3. The absolute difference between the proportion of people that prefer McDonald's and the proportion of people that prefer Wendy's, in a given random sample.\n",
    "3. The total variation distance between the proportion of people that prefer McDonald's and the proportion of people that prefer Wendy's, in a given random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_14 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.15.** Choose the best tool to answer the following question: <br>\n",
    "> What is the median tip amount left by all McDonald's customers?\n",
    "1. standard hypothesis testing\n",
    "2. permutation (A/B) testing\n",
    "3. bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_15 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finish Line\n",
    "\n",
    "Congratulations! You are done with homework 6.\n",
    "\n",
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
